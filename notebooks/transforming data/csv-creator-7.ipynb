{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Dropout,Conv2D,MaxPooling2D, BatchNormalization, LSTM\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.preprocessing import image\nfrom sklearn.metrics import accuracy_score,classification_report,confusion_matrix\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nimport os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras_preprocessing.image.dataframe_iterator import DataFrameIterator\nimport matplotlib.pyplot as plt\nimport pydicom\nimport scipy.ndimage\nfrom sklearn.cluster import KMeans\nfrom skimage import morphology\nfrom skimage import measure\nfrom skimage.transform import resize\nfrom glob import glob\nfrom skimage.io import imread\n\nlungs = load_model('/kaggle/input/lungs-detector/model.h5')\nlungs.load_weights('/kaggle/input/lungs-detector/model-weights.h5')\n\n#total studies 7278\ndf = pd.read_csv(\"/kaggle/input/rsna-str-pulmonary-embolism-detection/train.csv\")\nlst, sublst = [], []\nwatcher = ''\nskipper = 1\nskip_by = 6000\nlast = ''\nfirst_time = True\nfor idx, x in df.iterrows():\n        \n    if skipper >= skip_by:\n        \n        if first_time:\n            watcher = x['StudyInstanceUID']\n            first_time = False;\n        \n        if watcher != x['StudyInstanceUID']:\n            lst.append(sublst)\n            watcher = x['StudyInstanceUID']\n            sublst = []\n\n        else:\n            sublst += [x]\n            \n    elif last != x['StudyInstanceUID']:\n        skipper += 1\n    else:\n        last = x['StudyInstanceUID']\n        \n    if len(lst) >= 1278:\n        break\n\n        \ndef trans(img):\n    img_2d = img.astype(float)\n    img_2d_scaled = (np.maximum(img_2d,0) / img_2d.max()) * 255.0\n    img_2d_scaled = np.uint8(img_2d_scaled)\n    return img_2d_scaled\n\ndef load_scan(path):\n    slices = [pydicom.read_file(path + '/' + s) for s in os.listdir(path)]\n    slices.sort(key = lambda x: int(x.InstanceNumber))\n    copy = []\n    for i in range(len(slices)):\n        if i == 0:\n            copy.append([np.array(trans(slices[i].pixel_array)), str(slices[i].get(0x00080018).value), str(slices[i].get(0x00080018).value), str(slices[i+1].get(0x00080018).value)])\n        elif i == len(slices) - 1:\n            copy.append([np.array(trans(slices[i].pixel_array)), str(slices[i].get(0x00080018).value), str(slices[i-1].get(0x00080018).value), str(slices[i].get(0x00080018).value)])\n        else:\n            copy.append([np.array(trans(slices[i].pixel_array)), str(slices[i].get(0x00080018).value), str(slices[i-1].get(0x00080018).value), str(slices[i+1].get(0x00080018).value)])\n    \n    return copy\n\ndef check(x):\n    #get x[0] as in int is x is a 'pydicom.multival.MultiValue', otherwise get int(x)\n    if type(x) == pydicom.multival.MultiValue: return int(x[0])\n    else: return int(x)\n    \ndef window(path, WL=100, WW=700):\n    f = pydicom.dcmread(path)\n    intercept = check(f[('0028','1052')].value)\n    slope = check(f[('0028','1053')].value)\n    img = f.pixel_array\n    img = (img*slope +intercept) #for translation adjustments given in the dicom file. \n    upper, lower = WL+WW//2, WL-WW//2\n    X = np.clip(img.copy(), lower, upper)\n    X = X - np.min(X)\n    X = X / np.max(X)\n    X = (X*255.0).astype('uint8')\n    X = np.expand_dims(X, axis=2)\n    return X\n\ndef fuser(ds1,ds2,ds3):\n    img1 = window(ds1)\n    img2 = window(ds2)\n    img3 = window(ds3)\n    img = np.concatenate([img1,img2,img3], axis=2)\n    return img\n\ndef sample_stack(stack, rows=6, cols=6, start_with=0, show_every=0):\n\n    res = []\n    max_val = 0\n    white_sum = 600\n    filter_percentage = 0.7\n    filter_percentage2 = 0.6\n    filter_val = 0\n    \n        \n    def masker(img, w=64, h=64, threshold=200):\n        img = resize(img, (w,h))\n        img2 = img.reshape(1,w,h,1)\n        pred = lungs(img2, training=False).numpy()\n        pred = pred.reshape(w,h,1)\n        pred = trans(pred)\n        white = np.count_nonzero(np.all(pred>=[threshold], axis=2))\n        return pred, white\n\n    \n    if show_every == 0:\n        show_every = int( len(stack) / (rows * cols) )\n    \n    \n    for i in range(rows*cols):\n        ind = start_with + i * show_every\n        if ind > len(stack) - 1:\n            break\n        img = stack[ind][0] #pixel data\n        name = stack[ind][1] #SOP instance UID\n        before = stack[ind][2] # previous SOP instance UID\n        after = stack[ind][3] #next SOP instance UID\n        pred, white = masker(img)\n        \n        if max_val < white:\n            max_val = white\n        res.append([pred, white, name, before, after])\n        \n    if max_val < white_sum:\n        filter_val = max_val * filter_percentage\n    else:\n        filter_val = max_val * filter_percentage2\n    \n    final = []\n    hcount = 0\n    wcount = 0\n    limit = 8\n    for el in res:\n        if el[1] >= filter_val:\n            final.append([ el[2], el[3], el[4] ]) #adding the file names, before and after\n\n    \n    result = [final[int(len(final) * 0.2)],\n         final[int(len(final) * 0.3)],\n         final[int(len(final) * 0.4)],\n         final[int(len(final) * 0.5)],\n         final[int(len(final) * 0.6)],\n         final[int(len(final) * 0.7)]\n        ]\n        \n    return result\n        \n        \n    \nnew_file = pd.DataFrame(columns=['StudyInstanceUID','SeriesInstanceUID','SOPInstanceUID','pe_present_on_image','negative_exam_for_pe','qa_motion','qa_contrast','flow_artifact','rv_lv_ratio_gte_1','rv_lv_ratio_lt_1','leftsided_pe','chronic_pe','true_filling_defect_not_pe','rightsided_pe','acute_and_chronic_pe','central_pe','indeterminate','before','after','image'\n])\nfor el in lst:\n    data = load_scan('/kaggle/input/rsna-str-pulmonary-embolism-detection/train/' + el[0]['StudyInstanceUID']  + '/' + el[0]['SeriesInstanceUID'])\n    chosen_files = sample_stack(data)\n    \n    for e in el:\n        for c in chosen_files:\n            if e['SOPInstanceUID'] == c[0]:\n                temp = {'StudyInstanceUID':e['StudyInstanceUID'],\n                        'SeriesInstanceUID':e['SeriesInstanceUID'],\n                        'SOPInstanceUID':e['SOPInstanceUID'],\n                        'pe_present_on_image':e['pe_present_on_image'],\n                        'negative_exam_for_pe':e['negative_exam_for_pe'],\n                        'qa_motion':e['qa_motion'],\n                        'qa_contrast':e['qa_contrast'],\n                        'flow_artifact':e['flow_artifact'],\n                        'rv_lv_ratio_gte_1':e['rv_lv_ratio_gte_1'],\n                        'rv_lv_ratio_lt_1':e['rv_lv_ratio_lt_1'],\n                        'leftsided_pe':e['leftsided_pe'] * e['pe_present_on_image'],\n                        'chronic_pe':e['chronic_pe'] * e['pe_present_on_image'],\n                        'true_filling_defect_not_pe':e['true_filling_defect_not_pe'],\n                        'rightsided_pe':e['rightsided_pe'] * e['pe_present_on_image'],\n                        'acute_and_chronic_pe':e['acute_and_chronic_pe'] * e['pe_present_on_image'],\n                        'central_pe':e['central_pe'] * e['pe_present_on_image'],\n                        'indeterminate':e['indeterminate'],\n                        'before': c[1],\n                        'after': c[2],\n                        'image': 'csv_creator_7/{}-{}-{}.png'.format(e['StudyInstanceUID'], e['SeriesInstanceUID'], e['SOPInstanceUID'])\n                       }\n                new_file = pd.concat([new_file, pd.DataFrame([e])], ignore_index=True)\n                ds1 = '/kaggle/input/rsna-str-pulmonary-embolism-detection/train/{}/{}/{}.dcm'.format(e['StudyInstanceUID'], e['SeriesInstanceUID'], c[0])\n                ds2 = '/kaggle/input/rsna-str-pulmonary-embolism-detection/train/{}/{}/{}.dcm'.format(e['StudyInstanceUID'], e['SeriesInstanceUID'], c[1])\n                ds3 = '/kaggle/input/rsna-str-pulmonary-embolism-detection/train/{}/{}/{}.dcm'.format(e['StudyInstanceUID'], e['SeriesInstanceUID'], c[2])\n                img = fuser(ds1, ds2, ds3)\n                plt.imsave('{}-{}-{}.png'.format(e['StudyInstanceUID'], e['SeriesInstanceUID'], e['SOPInstanceUID']), img)\n                break\n            \nnew_file.to_csv('train.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}