{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom keras import layers\nfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\nfrom keras.models import Model, load_model\nfrom keras.initializers import glorot_uniform\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nimport keras.backend as K\nimport tensorflow as tf\nimport pydicom as di\nimport matplotlib.pyplot as plt\nimport pandas as pd","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"src = '/kaggle/input'\nx = 'image' #independent variables for DCMDataFrameIterator\ny = ['leftsided_pe','central_pe','rightsided_pe'] ##dependent variables for DCMDataFrameIterator\n#y = ['pe_present_on_image','leftsided_pe','central_pe','rightsided_pe','chronic_pe','acute_and_chronic_pe'] ##dependent variables for DCMDataFrameIterator\n\ndf1 = pd.read_csv(\"/kaggle/input/csv_creator_1/train.csv\")\ndf2 = pd.read_csv(\"/kaggle/input/csv_creator_2/train.csv\")\ndf3 = pd.read_csv(\"/kaggle/input/csv_creator_3/train.csv\")\ndf4 = pd.read_csv(\"/kaggle/input/csv_creator_4/train.csv\")\ndf5 = pd.read_csv(\"/kaggle/input/csv_creator_5/train.csv\")\ndf6 = pd.read_csv(\"/kaggle/input/csv_creator_6/train.csv\")\ndf7 = pd.read_csv(\"/kaggle/input/csv_creator_7/train.csv\")\ndf = pd.concat([df1,df2,df3,df4,df5,df6,df7], ignore_index=True)\ndf['leftsided_pe']*= df['pe_present_on_image']\ndf['rightsided_pe']*= df['pe_present_on_image']\ndf['central_pe']*= df['pe_present_on_image']\n\ntrain_df, test_df = train_test_split(df, test_size=0.1)\n\n# augmentation parameters\n# you can use preprocessing_function instead of rescale in all generators\n# if you are using a pretrained network\ntrain_augmentation_parameters = dict(\n    rescale=1.0/255.0,\n    rotation_range=5,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest',\n    brightness_range = [0.8, 1.2],\n    validation_split = 0.2\n)\n\nvalid_augmentation_parameters = dict(\n    rescale=1.0/255.0,\n    validation_split = 0.2\n)\n\ntest_augmentation_parameters = dict(\n    rescale=1.0/255.0\n)\n\n#<<=================================================================================================================================================>>\n# training parameters\nBATCH_SIZE = 32\nCLASS_MODE = 'raw'\nCOLOR_MODE = 'rgb'\nTARGET_SIZE = (512, 512)\nEPOCHS = 10\nSEED = 1337\n\ntrain_consts = {\n    'seed': SEED,\n    'batch_size': BATCH_SIZE,\n    'class_mode': CLASS_MODE,\n    'color_mode': COLOR_MODE,\n    'target_size': TARGET_SIZE,  \n    'subset': 'training',\n    'validate_filenames':False\n}\n\nvalid_consts = {\n    'seed': SEED,\n    'batch_size': BATCH_SIZE,\n    'class_mode': CLASS_MODE,\n    'color_mode': COLOR_MODE,\n    'target_size': TARGET_SIZE, \n    'subset': 'validation',\n    'validate_filenames':False\n}\n\ntest_consts = {\n    'batch_size': 32,  # should be 1 in testing\n    'class_mode': CLASS_MODE,\n    'color_mode': COLOR_MODE,\n    'target_size': TARGET_SIZE,  # resize input images\n    'shuffle': False,\n    'validate_filenames':False\n}\n\n#<<=================================================================================================================================================>>\n# Using the training phase generators \ntrain_augmenter = ImageDataGenerator(**train_augmentation_parameters)\nvalid_augmenter = ImageDataGenerator(**valid_augmentation_parameters)\ntest_augmenter = ImageDataGenerator(**test_augmentation_parameters)\n\n\ntrain_generator = train_augmenter.flow_from_dataframe(dataframe = train_df, directory=src, x_col=x, y_col=y, **train_consts)\n\nvalid_generator = valid_augmenter.flow_from_dataframe(dataframe = train_df, directory=src, x_col=x, y_col=y, **valid_consts)\n\ntest_generator = test_augmenter.flow_from_dataframe(dataframe = test_df, directory=src, x_col=x, y_col=y, **test_consts)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def identity_block(X, f, filters, stage, block):\n    # defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n\n    # Retrieve Filters\n    F1, F2, F3 = filters\n\n    # Save the input value. We'll need this later to add back to the main path. \n    X_shortcut = X\n\n    # First component of main path\n    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n\n    # Second component of main path\n    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path\n    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n\n    return X\n\n\n\ndef convolutional_block(X, f, filters, stage, block, s = 2):\n    # defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    # Retrieve Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value\n    X_shortcut = X\n\n\n    ##### MAIN PATH #####\n    # First component of main path \n    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n\n    # Second component of main path\n    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path\n    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n\n    \n    ##### SHORTCUT PATH ####\n    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n    \n    return X\n\n\ndef ResNet50(input_shape = (64, 64, 3), classes = 2):   \n    # Define the input as a tensor with shape input_shape\n    X_input = Input(input_shape)\n\n    # Zero-Padding\n    X = ZeroPadding2D((3, 3))(X_input)\n    \n    # Stage 1\n    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n\n    # Stage 2\n    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n\n    # Stage 3\n    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n\n    # Stage 4\n    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n\n    # Stage 5\n    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n\n    # AVGPOOL.\n    X = AveragePooling2D((2, 2), name='avg_pool')(X)\n\n    # output layer\n    X = Flatten()(X)\n    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n    \n    # Create model\n    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n\n    return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROWS = 512\nCOLS = 512\nCHANNELS = 3\nCLASSES = 3\nmodel = ResNet50(input_shape = (ROWS, COLS, CHANNELS), classes = CLASSES)\n#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\nmodel.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\nfilepath = \"best_model.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\ncallbacks_list = [checkpoint]\n\nhistory = model.fit(\ntrain_generator,\nepochs=EPOCHS,\nvalidation_data=valid_generator,\nverbose=1, \ncallbacks=callbacks_list\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('end_model.h5')\nmodel.save_weights('weights.h5')\nres = history.history\nfile = open('results.txt','a+')\nfile.write(str(res))\nfile.close()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(test_generator, steps=len(test_generator), batch_size=1)\nprint('test loss: {},  test_accuracy: {}'.format(test_loss, test_accuracy))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#loss graph\nplt.plot(history.history['loss'],label='train loss')\nplt.plot(history.history['val_loss'],label='val loss')\nplt.legend()\n\nplt.savefig('loss-graph.png')\nplt.show()\n\n# accuracies\nplt.plot(history.history['categorical_accuracy'], label='train acc')\nplt.plot(history.history['val_categorical_accuracy'], label='val acc')\nplt.legend()\n\n \nplt.savefig('acc-graph.png')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}