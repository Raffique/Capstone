{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom keras import layers\nfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, GlobalAveragePooling2D, Dropout\nfrom keras.layers import Lambda, LSTM\nfrom tensorflow.keras.optimizers import SGD\nfrom keras.models import Model, load_model, Sequential\nfrom keras.initializers import glorot_uniform\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nimport keras.backend as K\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nfrom keras.optimizers import adam_v2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n\ndf1 = pd.read_csv(\"/kaggle/input/csv-creator-1/train.csv\")\ndf1['image'] = 'csv-creator-1/' + df1['StudyInstanceUID'] + '-' + df1['SeriesInstanceUID'] + '-' + df1['SOPInstanceUID'] + '.png'\n\ndf2 = pd.read_csv(\"/kaggle/input/csv-creator-2/train.csv\")\ndf2['image'] = 'csv-creator-2/' + df2['StudyInstanceUID'] + '-' + df2['SeriesInstanceUID'] + '-' + df2['SOPInstanceUID'] + '.png'\n\ndf3 = pd.read_csv(\"/kaggle/input/csv-creator-3/train.csv\")\ndf3['image'] = 'csv-creator-3/' + df3['StudyInstanceUID'] + '-' + df3['SeriesInstanceUID'] + '-' + df3['SOPInstanceUID'] + '.png'\n\ndf4 = pd.read_csv(\"/kaggle/input/csv-creator-4/train.csv\")\ndf4['image'] = 'csv-creator-4/' + df4['StudyInstanceUID'] + '-' + df4['SeriesInstanceUID'] + '-' + df4['SOPInstanceUID'] + '.png'\n\ndf5 = pd.read_csv(\"/kaggle/input/csv-creator-5/train.csv\")\ndf5['image'] = 'csv-creator-5/' + df5['StudyInstanceUID'] + '-' + df5['SeriesInstanceUID'] + '-' + df5['SOPInstanceUID'] + '.png'\n\ndf6 = pd.read_csv(\"/kaggle/input/csv-creator-6/train.csv\")\ndf6['image'] = 'csv-creator-6/' + df6['StudyInstanceUID'] + '-' + df6['SeriesInstanceUID'] + '-' + df6['SOPInstanceUID'] + '.png'\n\ndf7 = pd.read_csv(\"/kaggle/input/csv-creator-7/train.csv\")\ndf7['image'] = 'csv-creator-7/' + df7['StudyInstanceUID'] + '-' + df7['SeriesInstanceUID'] + '-' + df7['SOPInstanceUID'] + '.png'\n\ndf = pd.concat([df1,df2,df3,df4,df5,df6,df7], ignore_index=True)\n#df['image'] = df['image'][:12].replace('csv_creator_', 'csv-creator-') + df['image'][12:] #forgot to place the initial paths for the image paths; addding it here :P\n\ndf.to_csv('train.csv')\n\n\ntrain_df, test_df = train_test_split(df, test_size=0.1)\n\n# augmentation parameters\n# you can use preprocessing_function instead of rescale in all generators\n# if you are using a pretrained network\ntrain_augmentation_parameters = dict(\n    rescale=1.0/255.0,\n    rotation_range=5,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest',\n    brightness_range = [0.8, 1.2],\n    validation_split = 0.2\n)\n\nvalid_augmentation_parameters = dict(\n    rescale=1.0/255.0,\n    validation_split = 0.2\n)\n\ntest_augmentation_parameters = dict(\n    rescale=1.0/255.0\n)\n\n#<<=================================================================================================================================================>>\n# training parameters\nBATCH_SIZE = 32\nCLASS_MODE = 'raw'\nCOLOR_MODE = 'rgb'\nTARGET_SIZE = (512, 512)\nEPOCHS = 10\nSEED = 1337\n\ntrain_consts = {\n    'seed': SEED,\n    'batch_size': BATCH_SIZE,\n    'class_mode': CLASS_MODE,\n    'color_mode': COLOR_MODE,\n    'target_size': TARGET_SIZE,  \n    'subset': 'training',\n    'validate_filenames':False\n}\n\nvalid_consts = {\n    'seed': SEED,\n    'batch_size': BATCH_SIZE,\n    'class_mode': CLASS_MODE,\n    'color_mode': COLOR_MODE,\n    'target_size': TARGET_SIZE, \n    'subset': 'validation',\n    'validate_filenames':False\n}\n\ntest_consts = {\n    'batch_size': 32,  # should be 1 in testing\n    'class_mode': CLASS_MODE,\n    'color_mode': COLOR_MODE,\n    'target_size': TARGET_SIZE,  # resize input images\n    'shuffle': False,\n    'validate_filenames':False\n}\n\n#<<=================================================================================================================================================>>\n\nsrc = '/kaggle/input'\nx = 'image' #independent variables for DCMDataFrameIterator\ny = ['pe_present_on_image'] ##dependent variables for DCMDataFrameIterator\n#y = ['pe_present_on_image','leftsided_pe','central_pe','rightsided_pe','chronic_pe','acute_and_chronic_pe']\n\n# Using the training phase generators \ntrain_augmenter = ImageDataGenerator(**train_augmentation_parameters)\nvalid_augmenter = ImageDataGenerator(**valid_augmentation_parameters)\ntest_augmenter = ImageDataGenerator(**test_augmentation_parameters)\n\n\ntrain_generator = train_augmenter.flow_from_dataframe(dataframe = train_df, directory=src, x_col=x, y_col=y, **train_consts)\n\nvalid_generator = valid_augmenter.flow_from_dataframe(dataframe = train_df, directory=src, x_col=x, y_col=y, **valid_consts)\n\ntest_generator = test_augmenter.flow_from_dataframe(dataframe = test_df, directory=src, x_col=x, y_col=y, **test_consts)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T10:36:18.654476Z","iopub.execute_input":"2022-05-12T10:36:18.654739Z","iopub.status.idle":"2022-05-12T10:36:19.291612Z","shell.execute_reply.started":"2022-05-12T10:36:18.65471Z","shell.execute_reply":"2022-05-12T10:36:19.290902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def identity_block(X, f, filters, stage, block):\n    # defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n\n    # Retrieve Filters\n    F1, F2, F3 = filters\n\n    # Save the input value. We'll need this later to add back to the main path. \n    X_shortcut = X\n\n    # First component of main path\n    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n\n    # Second component of main path\n    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path\n    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n\n    return X\n\n\n\ndef convolutional_block(X, f, filters, stage, block, s = 2):\n    # defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    # Retrieve Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value\n    X_shortcut = X\n\n\n    ##### MAIN PATH #####\n    # First component of main path \n    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n\n    # Second component of main path\n    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path\n    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n\n    \n    ##### SHORTCUT PATH ####\n    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n    \n    return X\n\n\ndef ResNet50_build(input_shape = (64, 64, 3), classes = 2):   \n    # Define the input as a tensor with shape input_shape\n    X_input = Input(input_shape)\n\n    # Zero-Padding\n    X = ZeroPadding2D((3, 3))(X_input)\n    \n    # Stage 1\n    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n\n    # Stage 2\n    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n\n    # Stage 3\n    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n\n    # Stage 4\n    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n\n    # Stage 5\n    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n\n    # AVGPOOL.\n    X = AveragePooling2D((2, 2), name='avg_pool')(X)\n\n    # output layer\n    X = Flatten()(X)\n    X = Dense(classes, activation='sigmoid', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n    \n    # Create model\n    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-11T10:42:21.888758Z","iopub.execute_input":"2022-05-11T10:42:21.889257Z","iopub.status.idle":"2022-05-11T10:42:21.917888Z","shell.execute_reply.started":"2022-05-11T10:42:21.88922Z","shell.execute_reply":"2022-05-11T10:42:21.917105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model(input_shape, classes):\n    inputs = Input(input_shape)\n    resnet = ResNet50(include_top=False, input_shape=input_shape) \n    x  = GlobalAveragePooling2D()(resnet(inputs))\n    x = Dropout(0.5)(x)\n    outputs = Dense(classes, activation='sigmoid')(x)\n\n    return Model(inputs, outputs)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T10:36:39.044373Z","iopub.execute_input":"2022-05-12T10:36:39.04481Z","iopub.status.idle":"2022-05-12T10:36:39.050336Z","shell.execute_reply.started":"2022-05-12T10:36:39.044774Z","shell.execute_reply":"2022-05-12T10:36:39.04949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROWS = 512\nCOLS = 512\nCHANNELS = 3\nCLASSES = 1\n\n#model = ResNet50_build_model(input_shape = (ROWS, COLS, CHANNELS), classes = CLASSES)\nmodel = build_model((ROWS, COLS, CHANNELS), CLASSES)\n\nmodel.compile(optimizer=adam_v2.Adam(learning_rate=0.0001, decay=0.00001), \n              loss='binary_crossentropy', \n              metrics=['binary_accuracy'])\n\nreduce_lr = ReduceLROnPlateau(monitor='val_binary_accuracy', \n                              factor=0.5, \n                              patience=2, \n                              verbose=1, \n                              mode='max', \n                              min_lr=0.000001)\n\ncheckpoint = ModelCheckpoint(\"best_model.h5\", \n                             monitor='loss', \n                             verbose=1, \n                             save_best_only=True, \n                             mode='min')\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-12T10:38:28.883451Z","iopub.execute_input":"2022-05-12T10:38:28.883705Z","iopub.status.idle":"2022-05-12T10:38:30.542862Z","shell.execute_reply.started":"2022-05-12T10:38:28.883677Z","shell.execute_reply":"2022-05-12T10:38:30.542166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_generator,\n                    epochs=EPOCHS,\n                    validation_data=valid_generator,\n                    verbose=1, \n                    callbacks=[checkpoint, reduce_lr]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(test_generator, steps=len(test_generator), batch_size=1)\nprint('test loss: {},  test_accuracy: {}'.format(test_loss, test_accuracy))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('model.h5')\nmodel.save_weights('weights.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#loss graph\nplt.plot(history.history['loss'],label='train loss')\nplt.plot(history.history['val_loss'],label='val loss')\nplt.legend()\n\nplt.savefig('loss-graph.png')\nplt.show()\n\n# accuracies\nplt.plot(history.history['binary_accuracy'], label='train acc')\nplt.plot(history.history['val_binary_accuracy'], label='val acc')\nplt.legend()\n\n \nplt.savefig('acc-graph.png')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}